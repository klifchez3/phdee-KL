# phd-ee homework 2 - python script for kwh analysis
# kelly lifchez
# 01/20/2025

# import libraries 
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import scipy.stats as sc
import scipy.optimize as opt

# Set working directories and seed

inputpath = r'/Users/kellylifchez/GaTech Dropbox/Kelly Lifchez/phdee-KL/homework2/data/raw'
outputpath = r'/Users/kellylifchez/GaTech Dropbox/Kelly Lifchez/phdee-KL/homework2/output'

#setting same seed as homework 1 for consistency 
np.random.seed(6578103)

# Load data - read in the kwh.csv file
df = pd.read_csv(os.path.join(inputpath, 'kwh.csv'))


### Question 1 - Balance Table

## set up 

# assign control and treatment groups  
control_group = df[df['retrofit'] == 0]
treatment_group = df[df['retrofit'] == 1.0]
# note: this ^ is one option - can also specify py equivalent of "if retrofit = 0" in the next steps

# store variable names (besides retrofit)
varlist = ['electricity', 'sqft', 'temp']

## means and standard deviations for each variable and treatment group
control_mean = df[ df[ 'retrofit' ] == 0 ].mean().drop('retrofit')
treatment_mean = df[ df[ 'retrofit' ] == 1 ].mean().drop('retrofit')

control_std = df[ df[ 'retrofit' ] == 0 ].std().drop('retrofit')
treatment_std = df[ df[ 'retrofit' ] == 1 ].std().drop('retrofit')

# difference in means / two-way t test
t_stat, p_val = sc.ttest_ind(df[df['retrofit'] == 0].drop('retrofit', axis=1), df[df['retrofit'] == 1].drop('retrofit', axis=1), equal_var=False)
p_val = pd.Series(p_val, index=df.columns.drop('retrofit'))

#tval, pval = sc.ttest_ind(df[ df[ 'retrofit' ] == 0 ].drop('retrofit',1) , df[ df[ 'retrofit' ] == 1 ].drop('retrofit',1) , equal_var = False)
#t_stat, p_val = stats.ttest_ind(df[ df[ 'retrofit' ] == 0 ].drop('retrofit',1) , df[ df[ 'retrofit' ] == 1 ].drop('retrofit',1) , equal_var = False)
# p_val = pd.Series(p_val,varlist)


## table prep!

# get number of observations 
nobs_control = pd.Series(df[ df[ 'retrofit' ] == 0 ].count().min()) #min is smallest count of non-null values across all vars for control group
nobs_treatment = pd.Series(df[ df[ 'retrofit' ] == 1 ].count().min())
nobs_total = pd.Series(df.count().min())

# display observations as integers
nobs_control = nobs_control.map('{:.0f}'.format)
nobs_treatment = nobs_treatment.map('{:.0f}'.format)
nobs_total = nobs_total.map('{:.0f}'.format)

# display means, standard deviations, and p-values to two decimal places

control_mean = control_mean.map('{:.2f}'.format)
treatment_mean = treatment_mean.map('{:.2f}'.format)
control_std = control_std.map('({:.2f})'.format)
treatment_std = treatment_std.map('({:.2f})'.format)
p_val = p_val.map('{:.2f}'.format)

# set up rows and columns
rowlist = varlist + ['Observations']

# rows: stack empty list for stdevs and capitalize varnames
rownames = pd.concat([pd.Series(x.capitalize() for x in rowlist),pd.Series([' ',' ',' '])],axis = 1).stack()
# columns: make two levels of column names
columnnames = [('Control','(s.d.)'),('Treatment','(s.d.)'),('P-Value',' ')] 

# stack std deviations under means
col0 = pd.concat([control_mean,control_std,nobs_control],axis = 1,keys = ['mean','std dev','obs']).stack()

col1 = pd.concat([treatment_mean,treatment_std,nobs_treatment],axis = 1,keys = ['mean','std dev','obs']).stack()

# create empty list of standard deviations for p-value columm
empty_std_list = [''] * len(p_val)

# Combine p-values with the empty standard deviations and number of observations
col2 = pd.concat([p_val, pd.Series(empty_std_list, index=p_val.index), nobs_total], axis=1, keys=['p value', 'std dev', 'obs']).stack()

#col2 = pd.concat([p_val,nobs_total],axis = 1,keys = ['p value',' ','obs']).stack()

# remove Pandas indices
col0 = col0.reset_index(drop = True)
col1 = col1.reset_index(drop = True)
col2 = col2.reset_index(drop = True)

# combine columns to create table

balancetable = pd.concat([col0,col1,col2],axis = 1)
balancetable.columns = pd.MultiIndex.from_tuples(columnnames)
balancetable.index = rownames

print(balancetable)
print(balancetable.to_latex())

# Output directly to LaTeX folder
os.chdir(outputpath) 
balancetable.to_latex('py_balancetable.tex')

# --------------------------------------------------------------
### Question 2 

# kernel density plot - using kdeplot instead of displot because displot figures are not turning out as expected
sns.kdeplot(df[ df[ 'retrofit' ] == 0 ]['electricity']) 
sns.kdeplot(df[ df[ 'retrofit' ] == 1 ]['electricity'])
plt.xlabel('kWh')
plt.legend(labels = ['Non-retrofitted households','Retrofitted households'], loc='best', bbox_to_anchor=(1, 1))
plt.savefig('kdensity.pdf',format='pdf') # I suggest saving to .pdf for highest quality
plt.show()

#--------------------------------------------------------------
### Question 3
## Part (a) - by hand using NumPy Arrays

# Set up NumPy matrices for OLS:

# convert electricity column to numpy array
Array_Y = df['electricity'].to_numpy()
# assigns number of rows to `nrows` (shape returns a tuple representing dimensions of array, comma after nrows restricts to first item in tuple which is # of rows)
nrows_a, = Array_Y.shape
constant = np.ones((nrows_a,1)) # Vector of ones for constant
Array_X = df.drop('electricity',axis = 1).to_numpy() #remove electricity column
Array_X = np.concatenate([constant,Array_X],axis = 1) # Add constant

# Run ols regression - Array_X is inputs/design matrix & Array_Y is output/response variable
olsest_a = np.matmul(np.linalg.inv((np.matmul(Array_X.T, Array_X))), np.matmul(Array_X.T, Array_Y)) #.T gives transpose of matrix

## Part (b) - using scipy.optimize

# Set up objective function
def my_leastsq(beta,Y,X):
    return np.sum((Y-np.matmul(X,beta))**2)

olsest_b = opt.minimize(my_leastsq,np.array([0,1,1,1]).T, args = (Array_Y, Array_X)).x 
nrows_b, = Array_Y.shape

## Part (c) - using statsmodels function.
ols_c = sm.OLS(df['electricity'],Array_X).fit()
olsest_c = ols_c.params.to_numpy()
nrows_c = ols_c.nobs

# Output table

# Row and column names
varnames_q3 = ['Constant', 'Sqft', 'Retrofit', 'Temperature','Observations']

rownames_q3 = pd.Series(varnames_q3)
colnames_q3 = pd.Series(['(a)','(b)','(c)'])

# append OLS estimates and number of observations, then set index and column names
resultstable = pd.DataFrame({
    '(a)': np.append(olsest_a, nrows_a),
    '(b)': np.append(olsest_b, nrows_b),
    '(c)': np.append(olsest_c, nrows_c)
}, index=rownames_q3)
resultstable = resultstable.reindex(index = ['Retrofit', 'Sqft', 'Temperature', 'Constant','Observations'])

# Format output values to display three decimal places and change order
resultstable[colnames_q3] = resultstable[colnames_q3].applymap(lambda x: f"{x:.3f}")
resultstable.loc['Observations', colnames_q3] = resultstable.loc['Observations', colnames_q3].astype(float).astype(int)
print(resultstable)

resultstable.to_latex('resultstable.tex')
